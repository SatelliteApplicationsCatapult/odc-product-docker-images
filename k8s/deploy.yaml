---
apiVersion: v1
kind: ConfigMap
metadata:
  name: datacube-conf
  namespace: odc-routine-products
data:
  datacube.conf: |
    [datacube]
    db_database: datacube

    # A blank host will use a local socket. Specify a hostname (such as localhost) to use TCP.
    db_hostname: datacubedb-postgresql.datacubedb.svc.cluster.local

    # Credentials are optional: you might have other Postgres authentication configured.
    # The default username is the current user id
    db_username: postgres

    # A blank password will fall back to default postgres driver authentication, such as reading your ~/.pgpass file.
    db_password: localuser1234
---
apiVersion: batch/v1
kind: Job
metadata:
  name: odc-products
  namespace: odc-routine-products
spec:
  parallelism: 1
  ttlSecondsAfterFinished: 3600
  template:
    metadata:
      name: odc-worker
    spec:
      initContainers:
      - name: init-worker
        image: busybox:1.28
        env:
          - name: REDIS_SERVICE_HOST
            value: "redis-master"
        command: ['sh', '-c', 'until nslookup $REDIS_SERVICE_HOST; do echo Waiting for redis-master; sleep 2; done;']
      containers:
      - name: odc-worker
        image: satapps/odc-products:0.0.84
        env:
          #- name: EXTRA_PIP_PACKAGES
          #  value: s3fs dask-ml --upgrade
          - name: PYTHONUNBUFFERED
            value: "0"
          - name: REDIS_SERVICE_HOST  # In the default configuration the Redis master and worker Pods are in teh same namespace
            value: "redis-master"
          - name: DASK_SCHEDULER_HOST
            value: "dask-scheduler.dask.svc.cluster.local"
          #- name: AWS_NO_SIGN_REQUEST  # This option might be used for buckets with public access rights. Available since GDAL 2.3.
          #  value: "YES"
          - name: AWS_ACCESS_KEY_ID
            value: "AKIAIOSFODNN7INVALID"
          - name: AWS_SECRET_ACCESS_KEY
            value: "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"
          - name: AWS_VIRTUAL_HOSTING
            value: "FALSE"
          - name: AWS_S3_ENDPOINT_URL
            value: "http://s3-uk-1.sa-catapult.co.uk"
        volumeMounts:
          - mountPath: /etc/datacube.conf
            name: datacube-conf
            subPath: datacube.conf
      restartPolicy: Never
      volumes:
        - configMap:
            defaultMode: 420
            name: datacube-conf
          name: datacube-conf
